{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00a9675",
   "metadata": {},
   "source": [
    "***Внимание! Первые 2 ячейки носят исключительно развлекательный характер***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51628d85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    #notebook { background: url('https://catherineasquithgallery.com/uploads/posts/2021-02/1613327820_211-p-krasivie-sinie-foni-stim-224.jpg') no-repeat center center fixed; }\n",
       "    #notebook { background-size: cover; }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "def set_background_image(url):\n",
    "    style = f\"\"\"\n",
    "    <style>\n",
    "    #notebook {{ background: url('{url}') no-repeat center center fixed; }}\n",
    "    #notebook {{ background-size: cover; }}\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    return HTML(style)\n",
    "set_background_image('https://catherineasquithgallery.com/uploads/posts/2021-02/1613327820_211-p-krasivie-sinie-foni-stim-224.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24950e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    #notebook { background: none; }\n",
       "    #notebook { background-color: white; } /* Вы можете изменить цвет, если стандартный цвет отличается */\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def set_default_background():\n",
    "    style = \"\"\"\n",
    "    <style>\n",
    "    #notebook { background: none; }\n",
    "    #notebook { background-color: white; } /* Вы можете изменить цвет, если стандартный цвет отличается */\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    return HTML(style)\n",
    "\n",
    "# Применить изменения\n",
    "set_default_background()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dfe91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import optuna\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn import preprocessing \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy import stats\n",
    "from sklearn import svm\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11b9894",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3428</td>\n",
       "      <td>1011.344581</td>\n",
       "      <td>438.381072</td>\n",
       "      <td>321.0</td>\n",
       "      <td>589.619305</td>\n",
       "      <td>1148.130280</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.756201</td>\n",
       "      <td>50.924624</td>\n",
       "      <td>875.171844</td>\n",
       "      <td>...</td>\n",
       "      <td>470.481763</td>\n",
       "      <td>78.443473</td>\n",
       "      <td>375.378277</td>\n",
       "      <td>478.240361</td>\n",
       "      <td>587.857966</td>\n",
       "      <td>768.894455</td>\n",
       "      <td>529.164985</td>\n",
       "      <td>0.682279</td>\n",
       "      <td>0.478104</td>\n",
       "      <td>3800.811615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>891</td>\n",
       "      <td>942.375712</td>\n",
       "      <td>447.162228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>540.546097</td>\n",
       "      <td>966.657784</td>\n",
       "      <td>273.0</td>\n",
       "      <td>8.005016</td>\n",
       "      <td>67.932006</td>\n",
       "      <td>836.132264</td>\n",
       "      <td>...</td>\n",
       "      <td>560.002800</td>\n",
       "      <td>66.223093</td>\n",
       "      <td>371.697051</td>\n",
       "      <td>398.708932</td>\n",
       "      <td>623.739439</td>\n",
       "      <td>711.924461</td>\n",
       "      <td>466.640938</td>\n",
       "      <td>0.573211</td>\n",
       "      <td>0.647826</td>\n",
       "      <td>3300.948320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9151</td>\n",
       "      <td>979.455000</td>\n",
       "      <td>481.659862</td>\n",
       "      <td>321.0</td>\n",
       "      <td>432.191071</td>\n",
       "      <td>1030.149806</td>\n",
       "      <td>273.0</td>\n",
       "      <td>8.298350</td>\n",
       "      <td>58.709709</td>\n",
       "      <td>950.795099</td>\n",
       "      <td>...</td>\n",
       "      <td>518.921206</td>\n",
       "      <td>85.336925</td>\n",
       "      <td>367.609930</td>\n",
       "      <td>313.711247</td>\n",
       "      <td>610.289615</td>\n",
       "      <td>779.249812</td>\n",
       "      <td>372.420956</td>\n",
       "      <td>0.618591</td>\n",
       "      <td>0.586573</td>\n",
       "      <td>3403.103567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>464.809073</td>\n",
       "      <td>321.0</td>\n",
       "      <td>456.285084</td>\n",
       "      <td>906.518926</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.849912</td>\n",
       "      <td>57.644737</td>\n",
       "      <td>828.461082</td>\n",
       "      <td>...</td>\n",
       "      <td>467.669740</td>\n",
       "      <td>63.061711</td>\n",
       "      <td>375.552670</td>\n",
       "      <td>316.210390</td>\n",
       "      <td>629.424303</td>\n",
       "      <td>803.015855</td>\n",
       "      <td>373.855127</td>\n",
       "      <td>0.686382</td>\n",
       "      <td>0.585461</td>\n",
       "      <td>3045.048884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9197</td>\n",
       "      <td>939.757445</td>\n",
       "      <td>472.667363</td>\n",
       "      <td>321.0</td>\n",
       "      <td>478.841898</td>\n",
       "      <td>1056.683796</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.591892</td>\n",
       "      <td>65.301764</td>\n",
       "      <td>894.635206</td>\n",
       "      <td>...</td>\n",
       "      <td>359.903834</td>\n",
       "      <td>76.713550</td>\n",
       "      <td>374.841871</td>\n",
       "      <td>310.166313</td>\n",
       "      <td>660.742601</td>\n",
       "      <td>721.105750</td>\n",
       "      <td>375.468077</td>\n",
       "      <td>0.891905</td>\n",
       "      <td>0.413196</td>\n",
       "      <td>3910.492010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3342</td>\n",
       "      <td>957.712516</td>\n",
       "      <td>495.384743</td>\n",
       "      <td>321.0</td>\n",
       "      <td>590.221441</td>\n",
       "      <td>581.915631</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.637713</td>\n",
       "      <td>63.812240</td>\n",
       "      <td>838.982660</td>\n",
       "      <td>...</td>\n",
       "      <td>456.822022</td>\n",
       "      <td>76.670968</td>\n",
       "      <td>372.215665</td>\n",
       "      <td>346.896422</td>\n",
       "      <td>636.824980</td>\n",
       "      <td>755.481638</td>\n",
       "      <td>410.708662</td>\n",
       "      <td>0.702681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2993.803264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9600</td>\n",
       "      <td>978.791314</td>\n",
       "      <td>523.643280</td>\n",
       "      <td>321.0</td>\n",
       "      <td>567.217261</td>\n",
       "      <td>1063.281140</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.558498</td>\n",
       "      <td>69.594550</td>\n",
       "      <td>865.609864</td>\n",
       "      <td>...</td>\n",
       "      <td>459.127072</td>\n",
       "      <td>83.845302</td>\n",
       "      <td>375.734412</td>\n",
       "      <td>314.631061</td>\n",
       "      <td>615.926508</td>\n",
       "      <td>652.882198</td>\n",
       "      <td>384.225611</td>\n",
       "      <td>0.699153</td>\n",
       "      <td>0.510657</td>\n",
       "      <td>4125.434457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>446.952277</td>\n",
       "      <td>321.0</td>\n",
       "      <td>577.347754</td>\n",
       "      <td>1031.745041</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.634532</td>\n",
       "      <td>50.946860</td>\n",
       "      <td>851.642839</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.348009</td>\n",
       "      <td>375.898819</td>\n",
       "      <td>244.167934</td>\n",
       "      <td>710.429326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>295.114793</td>\n",
       "      <td>0.987655</td>\n",
       "      <td>0.376411</td>\n",
       "      <td>4274.726729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>171</td>\n",
       "      <td>986.182525</td>\n",
       "      <td>475.285612</td>\n",
       "      <td>321.0</td>\n",
       "      <td>480.996433</td>\n",
       "      <td>916.753466</td>\n",
       "      <td>273.0</td>\n",
       "      <td>8.178373</td>\n",
       "      <td>67.979491</td>\n",
       "      <td>843.010060</td>\n",
       "      <td>...</td>\n",
       "      <td>383.688273</td>\n",
       "      <td>49.251230</td>\n",
       "      <td>373.250204</td>\n",
       "      <td>261.832308</td>\n",
       "      <td>647.980423</td>\n",
       "      <td>668.571444</td>\n",
       "      <td>329.811799</td>\n",
       "      <td>0.836617</td>\n",
       "      <td>0.472253</td>\n",
       "      <td>3861.601745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9431</td>\n",
       "      <td>1000.605209</td>\n",
       "      <td>441.318255</td>\n",
       "      <td>321.0</td>\n",
       "      <td>579.219223</td>\n",
       "      <td>1136.752076</td>\n",
       "      <td>273.0</td>\n",
       "      <td>8.020235</td>\n",
       "      <td>42.191795</td>\n",
       "      <td>758.267911</td>\n",
       "      <td>...</td>\n",
       "      <td>427.895682</td>\n",
       "      <td>68.427461</td>\n",
       "      <td>373.535517</td>\n",
       "      <td>359.111865</td>\n",
       "      <td>605.903358</td>\n",
       "      <td>568.544495</td>\n",
       "      <td>401.303660</td>\n",
       "      <td>0.750183</td>\n",
       "      <td>0.436615</td>\n",
       "      <td>4359.686532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4859</td>\n",
       "      <td>945.610654</td>\n",
       "      <td>441.829227</td>\n",
       "      <td>321.0</td>\n",
       "      <td>497.091753</td>\n",
       "      <td>1002.357634</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.280713</td>\n",
       "      <td>68.645311</td>\n",
       "      <td>852.892829</td>\n",
       "      <td>...</td>\n",
       "      <td>451.803815</td>\n",
       "      <td>75.178557</td>\n",
       "      <td>367.631299</td>\n",
       "      <td>381.964844</td>\n",
       "      <td>622.594255</td>\n",
       "      <td>705.800194</td>\n",
       "      <td>450.610155</td>\n",
       "      <td>0.710485</td>\n",
       "      <td>0.525743</td>\n",
       "      <td>3599.213623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8383</td>\n",
       "      <td>949.799943</td>\n",
       "      <td>479.914902</td>\n",
       "      <td>321.0</td>\n",
       "      <td>656.999998</td>\n",
       "      <td>1010.602698</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.971914</td>\n",
       "      <td>49.204879</td>\n",
       "      <td>821.445862</td>\n",
       "      <td>...</td>\n",
       "      <td>537.846540</td>\n",
       "      <td>72.575324</td>\n",
       "      <td>369.270022</td>\n",
       "      <td>374.707007</td>\n",
       "      <td>664.181339</td>\n",
       "      <td>788.998910</td>\n",
       "      <td>423.911886</td>\n",
       "      <td>0.596825</td>\n",
       "      <td>0.604018</td>\n",
       "      <td>3635.532152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3045</td>\n",
       "      <td>972.299841</td>\n",
       "      <td>441.874754</td>\n",
       "      <td>321.0</td>\n",
       "      <td>502.524079</td>\n",
       "      <td>878.205756</td>\n",
       "      <td>273.0</td>\n",
       "      <td>8.218789</td>\n",
       "      <td>67.832586</td>\n",
       "      <td>896.990223</td>\n",
       "      <td>...</td>\n",
       "      <td>487.283322</td>\n",
       "      <td>62.167672</td>\n",
       "      <td>370.824486</td>\n",
       "      <td>223.723186</td>\n",
       "      <td>616.429862</td>\n",
       "      <td>712.709665</td>\n",
       "      <td>291.555772</td>\n",
       "      <td>0.658754</td>\n",
       "      <td>0.625652</td>\n",
       "      <td>3644.352562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>451</td>\n",
       "      <td>990.064330</td>\n",
       "      <td>472.856052</td>\n",
       "      <td>321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>958.188138</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.878137</td>\n",
       "      <td>53.876976</td>\n",
       "      <td>896.475655</td>\n",
       "      <td>...</td>\n",
       "      <td>336.379831</td>\n",
       "      <td>79.502000</td>\n",
       "      <td>373.157527</td>\n",
       "      <td>360.033573</td>\n",
       "      <td>621.236575</td>\n",
       "      <td>824.633098</td>\n",
       "      <td>413.910549</td>\n",
       "      <td>0.954278</td>\n",
       "      <td>0.434029</td>\n",
       "      <td>3904.881090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9312</td>\n",
       "      <td>965.806556</td>\n",
       "      <td>475.167543</td>\n",
       "      <td>321.0</td>\n",
       "      <td>421.491819</td>\n",
       "      <td>1011.979168</td>\n",
       "      <td>273.0</td>\n",
       "      <td>8.036414</td>\n",
       "      <td>75.256599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>560.009691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>375.299886</td>\n",
       "      <td>315.515433</td>\n",
       "      <td>595.653674</td>\n",
       "      <td>719.129183</td>\n",
       "      <td>390.772032</td>\n",
       "      <td>0.573204</td>\n",
       "      <td>0.636451</td>\n",
       "      <td>3255.592175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6110</td>\n",
       "      <td>943.150097</td>\n",
       "      <td>455.216121</td>\n",
       "      <td>321.0</td>\n",
       "      <td>607.666143</td>\n",
       "      <td>1251.016334</td>\n",
       "      <td>273.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.986046</td>\n",
       "      <td>851.117461</td>\n",
       "      <td>...</td>\n",
       "      <td>385.892815</td>\n",
       "      <td>89.992646</td>\n",
       "      <td>368.867313</td>\n",
       "      <td>326.259701</td>\n",
       "      <td>631.025687</td>\n",
       "      <td>658.131675</td>\n",
       "      <td>382.245747</td>\n",
       "      <td>0.831837</td>\n",
       "      <td>0.380399</td>\n",
       "      <td>4655.238754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9349</td>\n",
       "      <td>967.068907</td>\n",
       "      <td>479.347057</td>\n",
       "      <td>321.0</td>\n",
       "      <td>494.302858</td>\n",
       "      <td>767.660825</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.778627</td>\n",
       "      <td>55.285905</td>\n",
       "      <td>841.046962</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.530176</td>\n",
       "      <td>376.231394</td>\n",
       "      <td>403.192330</td>\n",
       "      <td>662.638600</td>\n",
       "      <td>684.023867</td>\n",
       "      <td>458.478235</td>\n",
       "      <td>0.833326</td>\n",
       "      <td>0.602784</td>\n",
       "      <td>3174.224307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8358</td>\n",
       "      <td>942.214170</td>\n",
       "      <td>482.328424</td>\n",
       "      <td>321.0</td>\n",
       "      <td>402.330198</td>\n",
       "      <td>827.389242</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.561693</td>\n",
       "      <td>61.212545</td>\n",
       "      <td>814.342360</td>\n",
       "      <td>...</td>\n",
       "      <td>466.549629</td>\n",
       "      <td>67.362385</td>\n",
       "      <td>370.369666</td>\n",
       "      <td>432.919592</td>\n",
       "      <td>581.992301</td>\n",
       "      <td>693.509434</td>\n",
       "      <td>494.132137</td>\n",
       "      <td>0.688030</td>\n",
       "      <td>0.645297</td>\n",
       "      <td>2888.743409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5828</td>\n",
       "      <td>1002.186330</td>\n",
       "      <td>483.437365</td>\n",
       "      <td>321.0</td>\n",
       "      <td>561.480831</td>\n",
       "      <td>776.937428</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.262777</td>\n",
       "      <td>53.495818</td>\n",
       "      <td>822.667786</td>\n",
       "      <td>...</td>\n",
       "      <td>570.218048</td>\n",
       "      <td>89.956593</td>\n",
       "      <td>373.305496</td>\n",
       "      <td>351.802443</td>\n",
       "      <td>637.187112</td>\n",
       "      <td>707.267456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562943</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>3101.123648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7016</td>\n",
       "      <td>970.792946</td>\n",
       "      <td>474.920020</td>\n",
       "      <td>321.0</td>\n",
       "      <td>519.543215</td>\n",
       "      <td>995.133959</td>\n",
       "      <td>273.0</td>\n",
       "      <td>7.509621</td>\n",
       "      <td>49.282206</td>\n",
       "      <td>898.039671</td>\n",
       "      <td>...</td>\n",
       "      <td>434.092701</td>\n",
       "      <td>69.599462</td>\n",
       "      <td>375.000172</td>\n",
       "      <td>313.363219</td>\n",
       "      <td>616.131101</td>\n",
       "      <td>745.144544</td>\n",
       "      <td>362.645425</td>\n",
       "      <td>0.739473</td>\n",
       "      <td>0.506155</td>\n",
       "      <td>3708.830436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    feature_1   feature_2  feature_3   feature_4    feature_5  \\\n",
       "0         3428  1011.344581  438.381072      321.0  589.619305  1148.130280   \n",
       "1          891   942.375712  447.162228        NaN  540.546097   966.657784   \n",
       "2         9151   979.455000  481.659862      321.0  432.191071  1030.149806   \n",
       "3         2195          NaN  464.809073      321.0  456.285084   906.518926   \n",
       "4         9197   939.757445  472.667363      321.0  478.841898  1056.683796   \n",
       "5         3342   957.712516  495.384743      321.0  590.221441   581.915631   \n",
       "6         9600   978.791314  523.643280      321.0  567.217261  1063.281140   \n",
       "7         6496          NaN  446.952277      321.0  577.347754  1031.745041   \n",
       "8          171   986.182525  475.285612      321.0  480.996433   916.753466   \n",
       "9         9431  1000.605209  441.318255      321.0  579.219223  1136.752076   \n",
       "10        4859   945.610654  441.829227      321.0  497.091753  1002.357634   \n",
       "11        8383   949.799943  479.914902      321.0  656.999998  1010.602698   \n",
       "12        3045   972.299841  441.874754      321.0  502.524079   878.205756   \n",
       "13         451   990.064330  472.856052      321.0         NaN   958.188138   \n",
       "14        9312   965.806556  475.167543      321.0  421.491819  1011.979168   \n",
       "15        6110   943.150097  455.216121      321.0  607.666143  1251.016334   \n",
       "16        9349   967.068907  479.347057      321.0  494.302858   767.660825   \n",
       "17        8358   942.214170  482.328424      321.0  402.330198   827.389242   \n",
       "18        5828  1002.186330  483.437365      321.0  561.480831   776.937428   \n",
       "19        7016   970.792946  474.920020      321.0  519.543215   995.133959   \n",
       "\n",
       "    feature_6  feature_7  feature_8   feature_9  ...  feature_13  feature_14  \\\n",
       "0       273.0   7.756201  50.924624  875.171844  ...  470.481763   78.443473   \n",
       "1       273.0   8.005016  67.932006  836.132264  ...  560.002800   66.223093   \n",
       "2       273.0   8.298350  58.709709  950.795099  ...  518.921206   85.336925   \n",
       "3       273.0   7.849912  57.644737  828.461082  ...  467.669740   63.061711   \n",
       "4       273.0   7.591892  65.301764  894.635206  ...  359.903834   76.713550   \n",
       "5       273.0   7.637713  63.812240  838.982660  ...  456.822022   76.670968   \n",
       "6       273.0   7.558498  69.594550  865.609864  ...  459.127072   83.845302   \n",
       "7       273.0   7.634532  50.946860  851.642839  ...         NaN   63.348009   \n",
       "8       273.0   8.178373  67.979491  843.010060  ...  383.688273   49.251230   \n",
       "9       273.0   8.020235  42.191795  758.267911  ...  427.895682   68.427461   \n",
       "10      273.0   7.280713  68.645311  852.892829  ...  451.803815   75.178557   \n",
       "11      273.0   7.971914  49.204879  821.445862  ...  537.846540   72.575324   \n",
       "12      273.0   8.218789  67.832586  896.990223  ...  487.283322   62.167672   \n",
       "13      273.0   7.878137  53.876976  896.475655  ...  336.379831   79.502000   \n",
       "14      273.0   8.036414  75.256599         NaN  ...  560.009691         NaN   \n",
       "15      273.0        NaN  55.986046  851.117461  ...  385.892815   89.992646   \n",
       "16      273.0   7.778627  55.285905  841.046962  ...         NaN   77.530176   \n",
       "17      273.0   7.561693  61.212545  814.342360  ...  466.549629   67.362385   \n",
       "18      273.0   7.262777  53.495818  822.667786  ...  570.218048   89.956593   \n",
       "19      273.0   7.509621  49.282206  898.039671  ...  434.092701   69.599462   \n",
       "\n",
       "    feature_15  feature_16  feature_17  feature_18  feature_19  feature_20  \\\n",
       "0   375.378277  478.240361  587.857966  768.894455  529.164985    0.682279   \n",
       "1   371.697051  398.708932  623.739439  711.924461  466.640938    0.573211   \n",
       "2   367.609930  313.711247  610.289615  779.249812  372.420956    0.618591   \n",
       "3   375.552670  316.210390  629.424303  803.015855  373.855127    0.686382   \n",
       "4   374.841871  310.166313  660.742601  721.105750  375.468077    0.891905   \n",
       "5   372.215665  346.896422  636.824980  755.481638  410.708662    0.702681   \n",
       "6   375.734412  314.631061  615.926508  652.882198  384.225611    0.699153   \n",
       "7   375.898819  244.167934  710.429326         NaN  295.114793    0.987655   \n",
       "8   373.250204  261.832308  647.980423  668.571444  329.811799    0.836617   \n",
       "9   373.535517  359.111865  605.903358  568.544495  401.303660    0.750183   \n",
       "10  367.631299  381.964844  622.594255  705.800194  450.610155    0.710485   \n",
       "11  369.270022  374.707007  664.181339  788.998910  423.911886    0.596825   \n",
       "12  370.824486  223.723186  616.429862  712.709665  291.555772    0.658754   \n",
       "13  373.157527  360.033573  621.236575  824.633098  413.910549    0.954278   \n",
       "14  375.299886  315.515433  595.653674  719.129183  390.772032    0.573204   \n",
       "15  368.867313  326.259701  631.025687  658.131675  382.245747    0.831837   \n",
       "16  376.231394  403.192330  662.638600  684.023867  458.478235    0.833326   \n",
       "17  370.369666  432.919592  581.992301  693.509434  494.132137    0.688030   \n",
       "18  373.305496  351.802443  637.187112  707.267456         NaN    0.562943   \n",
       "19  375.000172  313.363219  616.131101  745.144544  362.645425    0.739473   \n",
       "\n",
       "    feature_21       target  \n",
       "0     0.478104  3800.811615  \n",
       "1     0.647826  3300.948320  \n",
       "2     0.586573  3403.103567  \n",
       "3     0.585461  3045.048884  \n",
       "4     0.413196  3910.492010  \n",
       "5          NaN  2993.803264  \n",
       "6     0.510657  4125.434457  \n",
       "7     0.376411  4274.726729  \n",
       "8     0.472253  3861.601745  \n",
       "9     0.436615  4359.686532  \n",
       "10    0.525743  3599.213623  \n",
       "11    0.604018  3635.532152  \n",
       "12    0.625652  3644.352562  \n",
       "13    0.434029  3904.881090  \n",
       "14    0.636451  3255.592175  \n",
       "15    0.380399  4655.238754  \n",
       "16    0.602784  3174.224307  \n",
       "17    0.645297  2888.743409  \n",
       "18    0.849714  3101.123648  \n",
       "19    0.506155  3708.830436  \n",
       "\n",
       "[20 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('train-HW_BHW-sid_13.csv')\n",
    "c = data.corr()\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(c)\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24306f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[689.  nan]\n",
      "[321.  nan]\n",
      "[273.  nan]\n"
     ]
    }
   ],
   "source": [
    "print(data['feature_11'].unique())\n",
    "print(data['feature_3'].unique())\n",
    "print(data['feature_6'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76e9f7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'feature_1', 'feature_2', 'feature_4', 'feature_5', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'target']\n"
     ]
    }
   ],
   "source": [
    "columns_list = list(data.columns)\n",
    "columns_list.remove('feature_3')\n",
    "columns_list.remove('feature_6')\n",
    "columns_list.remove('feature_11')\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7a7d2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0  имеет  8000  уникальных значений\n",
      "feature_1  имеет  7803  уникальных значений\n",
      "feature_2  имеет  7800  уникальных значений\n",
      "feature_4  имеет  7831  уникальных значений\n",
      "feature_5  имеет  7820  уникальных значений\n",
      "feature_7  имеет  7815  уникальных значений\n",
      "feature_8  имеет  7808  уникальных значений\n",
      "feature_9  имеет  7822  уникальных значений\n",
      "feature_10  имеет  7800  уникальных значений\n",
      "feature_12  имеет  7825  уникальных значений\n",
      "feature_13  имеет  7799  уникальных значений\n",
      "feature_14  имеет  7817  уникальных значений\n",
      "feature_15  имеет  7844  уникальных значений\n",
      "feature_16  имеет  7824  уникальных значений\n",
      "feature_17  имеет  7799  уникальных значений\n",
      "feature_18  имеет  7812  уникальных значений\n",
      "feature_19  имеет  7799  уникальных значений\n",
      "feature_20  имеет  7816  уникальных значений\n",
      "feature_21  имеет  7803  уникальных значений\n",
      "target  имеет  8000  уникальных значений\n"
     ]
    }
   ],
   "source": [
    "data = data[columns_list]\n",
    "for column in columns_list:\n",
    "    print(column,' имеет ',len(data[column].unique()),' уникальных значений') #нет категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49354f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.02035</td>\n",
       "      <td>0.116199</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>0.709158</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>-0.013241</td>\n",
       "      <td>0.042316</td>\n",
       "      <td>-0.124572</td>\n",
       "      <td>0.118347</td>\n",
       "      <td>-0.362811</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>-0.213248</td>\n",
       "      <td>0.093178</td>\n",
       "      <td>-0.283975</td>\n",
       "      <td>-0.210314</td>\n",
       "      <td>0.347585</td>\n",
       "      <td>-0.752279</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  feature_1  feature_2  feature_4  feature_5  feature_7  \\\n",
       "target    -0.02035   0.116199    0.01557   0.427906   0.709158   0.002059   \n",
       "\n",
       "        feature_8  feature_9  feature_10  feature_12  feature_13  feature_14  \\\n",
       "target  -0.013241   0.042316   -0.124572    0.118347   -0.362811    0.001877   \n",
       "\n",
       "        feature_15  feature_16  feature_17  feature_18  feature_19  \\\n",
       "target    0.010342   -0.213248    0.093178   -0.283975   -0.210314   \n",
       "\n",
       "        feature_20  feature_21  target  \n",
       "target    0.347585   -0.752279     1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_4', 'feature_5', 'feature_13', 'feature_16', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'target']\n"
     ]
    }
   ],
   "source": [
    "c = data.corr()\n",
    "display(c.tail(1)) # df.tail(n) - возвращает последние n строк\n",
    "corr_coef = c.tail(1)\n",
    "important_features = []\n",
    "for column in columns_list:\n",
    "    if abs(corr_coef[column].values) > 0.2:\n",
    "        important_features.append(column)\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349ff0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589.619305</td>\n",
       "      <td>1148.130280</td>\n",
       "      <td>470.481763</td>\n",
       "      <td>478.240361</td>\n",
       "      <td>768.894455</td>\n",
       "      <td>529.164985</td>\n",
       "      <td>0.682279</td>\n",
       "      <td>0.478104</td>\n",
       "      <td>3800.811615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.546097</td>\n",
       "      <td>966.657784</td>\n",
       "      <td>560.002800</td>\n",
       "      <td>398.708932</td>\n",
       "      <td>711.924461</td>\n",
       "      <td>466.640938</td>\n",
       "      <td>0.573211</td>\n",
       "      <td>0.647826</td>\n",
       "      <td>3300.948320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>432.191071</td>\n",
       "      <td>1030.149806</td>\n",
       "      <td>518.921206</td>\n",
       "      <td>313.711247</td>\n",
       "      <td>779.249812</td>\n",
       "      <td>372.420956</td>\n",
       "      <td>0.618591</td>\n",
       "      <td>0.586573</td>\n",
       "      <td>3403.103567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>456.285084</td>\n",
       "      <td>906.518926</td>\n",
       "      <td>467.669740</td>\n",
       "      <td>316.210390</td>\n",
       "      <td>803.015855</td>\n",
       "      <td>373.855127</td>\n",
       "      <td>0.686382</td>\n",
       "      <td>0.585461</td>\n",
       "      <td>3045.048884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>478.841898</td>\n",
       "      <td>1056.683796</td>\n",
       "      <td>359.903834</td>\n",
       "      <td>310.166313</td>\n",
       "      <td>721.105750</td>\n",
       "      <td>375.468077</td>\n",
       "      <td>0.891905</td>\n",
       "      <td>0.413196</td>\n",
       "      <td>3910.492010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>590.221441</td>\n",
       "      <td>581.915631</td>\n",
       "      <td>456.822022</td>\n",
       "      <td>346.896422</td>\n",
       "      <td>755.481638</td>\n",
       "      <td>410.708662</td>\n",
       "      <td>0.702681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2993.803264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>567.217261</td>\n",
       "      <td>1063.281140</td>\n",
       "      <td>459.127072</td>\n",
       "      <td>314.631061</td>\n",
       "      <td>652.882198</td>\n",
       "      <td>384.225611</td>\n",
       "      <td>0.699153</td>\n",
       "      <td>0.510657</td>\n",
       "      <td>4125.434457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>577.347754</td>\n",
       "      <td>1031.745041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>244.167934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>295.114793</td>\n",
       "      <td>0.987655</td>\n",
       "      <td>0.376411</td>\n",
       "      <td>4274.726729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>480.996433</td>\n",
       "      <td>916.753466</td>\n",
       "      <td>383.688273</td>\n",
       "      <td>261.832308</td>\n",
       "      <td>668.571444</td>\n",
       "      <td>329.811799</td>\n",
       "      <td>0.836617</td>\n",
       "      <td>0.472253</td>\n",
       "      <td>3861.601745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>579.219223</td>\n",
       "      <td>1136.752076</td>\n",
       "      <td>427.895682</td>\n",
       "      <td>359.111865</td>\n",
       "      <td>568.544495</td>\n",
       "      <td>401.303660</td>\n",
       "      <td>0.750183</td>\n",
       "      <td>0.436615</td>\n",
       "      <td>4359.686532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>497.091753</td>\n",
       "      <td>1002.357634</td>\n",
       "      <td>451.803815</td>\n",
       "      <td>381.964844</td>\n",
       "      <td>705.800194</td>\n",
       "      <td>450.610155</td>\n",
       "      <td>0.710485</td>\n",
       "      <td>0.525743</td>\n",
       "      <td>3599.213623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>656.999998</td>\n",
       "      <td>1010.602698</td>\n",
       "      <td>537.846540</td>\n",
       "      <td>374.707007</td>\n",
       "      <td>788.998910</td>\n",
       "      <td>423.911886</td>\n",
       "      <td>0.596825</td>\n",
       "      <td>0.604018</td>\n",
       "      <td>3635.532152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>502.524079</td>\n",
       "      <td>878.205756</td>\n",
       "      <td>487.283322</td>\n",
       "      <td>223.723186</td>\n",
       "      <td>712.709665</td>\n",
       "      <td>291.555772</td>\n",
       "      <td>0.658754</td>\n",
       "      <td>0.625652</td>\n",
       "      <td>3644.352562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>958.188138</td>\n",
       "      <td>336.379831</td>\n",
       "      <td>360.033573</td>\n",
       "      <td>824.633098</td>\n",
       "      <td>413.910549</td>\n",
       "      <td>0.954278</td>\n",
       "      <td>0.434029</td>\n",
       "      <td>3904.881090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>421.491819</td>\n",
       "      <td>1011.979168</td>\n",
       "      <td>560.009691</td>\n",
       "      <td>315.515433</td>\n",
       "      <td>719.129183</td>\n",
       "      <td>390.772032</td>\n",
       "      <td>0.573204</td>\n",
       "      <td>0.636451</td>\n",
       "      <td>3255.592175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>607.666143</td>\n",
       "      <td>1251.016334</td>\n",
       "      <td>385.892815</td>\n",
       "      <td>326.259701</td>\n",
       "      <td>658.131675</td>\n",
       "      <td>382.245747</td>\n",
       "      <td>0.831837</td>\n",
       "      <td>0.380399</td>\n",
       "      <td>4655.238754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>494.302858</td>\n",
       "      <td>767.660825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>403.192330</td>\n",
       "      <td>684.023867</td>\n",
       "      <td>458.478235</td>\n",
       "      <td>0.833326</td>\n",
       "      <td>0.602784</td>\n",
       "      <td>3174.224307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>402.330198</td>\n",
       "      <td>827.389242</td>\n",
       "      <td>466.549629</td>\n",
       "      <td>432.919592</td>\n",
       "      <td>693.509434</td>\n",
       "      <td>494.132137</td>\n",
       "      <td>0.688030</td>\n",
       "      <td>0.645297</td>\n",
       "      <td>2888.743409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>561.480831</td>\n",
       "      <td>776.937428</td>\n",
       "      <td>570.218048</td>\n",
       "      <td>351.802443</td>\n",
       "      <td>707.267456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562943</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>3101.123648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>519.543215</td>\n",
       "      <td>995.133959</td>\n",
       "      <td>434.092701</td>\n",
       "      <td>313.363219</td>\n",
       "      <td>745.144544</td>\n",
       "      <td>362.645425</td>\n",
       "      <td>0.739473</td>\n",
       "      <td>0.506155</td>\n",
       "      <td>3708.830436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_4    feature_5  feature_13  feature_16  feature_18  feature_19  \\\n",
       "0   589.619305  1148.130280  470.481763  478.240361  768.894455  529.164985   \n",
       "1   540.546097   966.657784  560.002800  398.708932  711.924461  466.640938   \n",
       "2   432.191071  1030.149806  518.921206  313.711247  779.249812  372.420956   \n",
       "3   456.285084   906.518926  467.669740  316.210390  803.015855  373.855127   \n",
       "4   478.841898  1056.683796  359.903834  310.166313  721.105750  375.468077   \n",
       "5   590.221441   581.915631  456.822022  346.896422  755.481638  410.708662   \n",
       "6   567.217261  1063.281140  459.127072  314.631061  652.882198  384.225611   \n",
       "7   577.347754  1031.745041         NaN  244.167934         NaN  295.114793   \n",
       "8   480.996433   916.753466  383.688273  261.832308  668.571444  329.811799   \n",
       "9   579.219223  1136.752076  427.895682  359.111865  568.544495  401.303660   \n",
       "10  497.091753  1002.357634  451.803815  381.964844  705.800194  450.610155   \n",
       "11  656.999998  1010.602698  537.846540  374.707007  788.998910  423.911886   \n",
       "12  502.524079   878.205756  487.283322  223.723186  712.709665  291.555772   \n",
       "13         NaN   958.188138  336.379831  360.033573  824.633098  413.910549   \n",
       "14  421.491819  1011.979168  560.009691  315.515433  719.129183  390.772032   \n",
       "15  607.666143  1251.016334  385.892815  326.259701  658.131675  382.245747   \n",
       "16  494.302858   767.660825         NaN  403.192330  684.023867  458.478235   \n",
       "17  402.330198   827.389242  466.549629  432.919592  693.509434  494.132137   \n",
       "18  561.480831   776.937428  570.218048  351.802443  707.267456         NaN   \n",
       "19  519.543215   995.133959  434.092701  313.363219  745.144544  362.645425   \n",
       "\n",
       "    feature_20  feature_21       target  \n",
       "0     0.682279    0.478104  3800.811615  \n",
       "1     0.573211    0.647826  3300.948320  \n",
       "2     0.618591    0.586573  3403.103567  \n",
       "3     0.686382    0.585461  3045.048884  \n",
       "4     0.891905    0.413196  3910.492010  \n",
       "5     0.702681         NaN  2993.803264  \n",
       "6     0.699153    0.510657  4125.434457  \n",
       "7     0.987655    0.376411  4274.726729  \n",
       "8     0.836617    0.472253  3861.601745  \n",
       "9     0.750183    0.436615  4359.686532  \n",
       "10    0.710485    0.525743  3599.213623  \n",
       "11    0.596825    0.604018  3635.532152  \n",
       "12    0.658754    0.625652  3644.352562  \n",
       "13    0.954278    0.434029  3904.881090  \n",
       "14    0.573204    0.636451  3255.592175  \n",
       "15    0.831837    0.380399  4655.238754  \n",
       "16    0.833326    0.602784  3174.224307  \n",
       "17    0.688030    0.645297  2888.743409  \n",
       "18    0.562943    0.849714  3101.123648  \n",
       "19    0.739473    0.506155  3708.830436  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[important_features]\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f2879ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   feature_4   8000 non-null   float64\n",
      " 1   feature_5   8000 non-null   float64\n",
      " 2   feature_13  8000 non-null   float64\n",
      " 3   feature_16  8000 non-null   float64\n",
      " 4   feature_18  8000 non-null   float64\n",
      " 5   feature_19  8000 non-null   float64\n",
      " 6   feature_20  8000 non-null   float64\n",
      " 7   feature_21  8000 non-null   float64\n",
      " 8   target      8000 non-null   float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 562.6 KB\n"
     ]
    }
   ],
   "source": [
    "for column in important_features:\n",
    "    value = data[column].mean()\n",
    "    data[column].fillna(value,inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03d3504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.815085e-01</td>\n",
       "      <td>1.241897</td>\n",
       "      <td>6.025191e-02</td>\n",
       "      <td>2.989976</td>\n",
       "      <td>0.586640</td>\n",
       "      <td>2.825037</td>\n",
       "      <td>-0.212562</td>\n",
       "      <td>-0.742305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.333640e-02</td>\n",
       "      <td>0.028713</td>\n",
       "      <td>1.204098e+00</td>\n",
       "      <td>1.441944</td>\n",
       "      <td>-0.282662</td>\n",
       "      <td>1.621808</td>\n",
       "      <td>-1.030697</td>\n",
       "      <td>0.572066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.429926e+00</td>\n",
       "      <td>0.453171</td>\n",
       "      <td>6.791818e-01</td>\n",
       "      <td>-0.212485</td>\n",
       "      <td>0.744652</td>\n",
       "      <td>-0.191386</td>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.097709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.106776e+00</td>\n",
       "      <td>-0.373329</td>\n",
       "      <td>2.432158e-02</td>\n",
       "      <td>-0.163841</td>\n",
       "      <td>1.107297</td>\n",
       "      <td>-0.163787</td>\n",
       "      <td>-0.181789</td>\n",
       "      <td>0.089097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.042431e-01</td>\n",
       "      <td>0.630557</td>\n",
       "      <td>-1.352646e+00</td>\n",
       "      <td>-0.281485</td>\n",
       "      <td>-0.142565</td>\n",
       "      <td>-0.132747</td>\n",
       "      <td>1.359871</td>\n",
       "      <td>-1.244967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.895844e-01</td>\n",
       "      <td>-2.543375</td>\n",
       "      <td>-1.142840e-01</td>\n",
       "      <td>0.433445</td>\n",
       "      <td>0.381975</td>\n",
       "      <td>0.545432</td>\n",
       "      <td>-0.059528</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.810513e-01</td>\n",
       "      <td>0.674661</td>\n",
       "      <td>-8.483148e-02</td>\n",
       "      <td>-0.194581</td>\n",
       "      <td>-1.183585</td>\n",
       "      <td>0.035786</td>\n",
       "      <td>-0.085991</td>\n",
       "      <td>-0.490201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.169219e-01</td>\n",
       "      <td>0.463835</td>\n",
       "      <td>-7.263109e-16</td>\n",
       "      <td>-1.566104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.679087</td>\n",
       "      <td>2.078106</td>\n",
       "      <td>-1.529837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-7.753464e-01</td>\n",
       "      <td>-0.304909</td>\n",
       "      <td>-1.048743e+00</td>\n",
       "      <td>-1.222277</td>\n",
       "      <td>-0.944183</td>\n",
       "      <td>-1.011368</td>\n",
       "      <td>0.945145</td>\n",
       "      <td>-0.787615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.420221e-01</td>\n",
       "      <td>1.165831</td>\n",
       "      <td>-4.838873e-01</td>\n",
       "      <td>0.671211</td>\n",
       "      <td>-2.470490</td>\n",
       "      <td>0.364440</td>\n",
       "      <td>0.296793</td>\n",
       "      <td>-1.063603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-5.594752e-01</td>\n",
       "      <td>0.267374</td>\n",
       "      <td>-1.784036e-01</td>\n",
       "      <td>1.116031</td>\n",
       "      <td>-0.376112</td>\n",
       "      <td>1.313307</td>\n",
       "      <td>-0.000984</td>\n",
       "      <td>-0.373375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.585221e+00</td>\n",
       "      <td>0.322494</td>\n",
       "      <td>9.209983e-01</td>\n",
       "      <td>0.974761</td>\n",
       "      <td>0.893413</td>\n",
       "      <td>0.799519</td>\n",
       "      <td>-0.853571</td>\n",
       "      <td>0.232804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-4.866166e-01</td>\n",
       "      <td>-0.562609</td>\n",
       "      <td>2.749321e-01</td>\n",
       "      <td>-1.964049</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-1.747577</td>\n",
       "      <td>-0.389026</td>\n",
       "      <td>0.400345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.524773e-15</td>\n",
       "      <td>-0.027909</td>\n",
       "      <td>-1.653222e+00</td>\n",
       "      <td>0.689152</td>\n",
       "      <td>1.437153</td>\n",
       "      <td>0.607050</td>\n",
       "      <td>1.827744</td>\n",
       "      <td>-1.083627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.573425e+00</td>\n",
       "      <td>0.331696</td>\n",
       "      <td>1.204186e+00</td>\n",
       "      <td>-0.177367</td>\n",
       "      <td>-0.172725</td>\n",
       "      <td>0.161767</td>\n",
       "      <td>-1.030749</td>\n",
       "      <td>0.483975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.235535e-01</td>\n",
       "      <td>1.929713</td>\n",
       "      <td>-1.020575e+00</td>\n",
       "      <td>0.031763</td>\n",
       "      <td>-1.103483</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>0.909294</td>\n",
       "      <td>-1.498954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-5.968800e-01</td>\n",
       "      <td>-1.301626</td>\n",
       "      <td>-7.263109e-16</td>\n",
       "      <td>1.529211</td>\n",
       "      <td>-0.708396</td>\n",
       "      <td>1.464723</td>\n",
       "      <td>0.920463</td>\n",
       "      <td>0.223249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.830422e+00</td>\n",
       "      <td>-0.902329</td>\n",
       "      <td>1.000947e-02</td>\n",
       "      <td>2.107834</td>\n",
       "      <td>-0.563656</td>\n",
       "      <td>2.150856</td>\n",
       "      <td>-0.169427</td>\n",
       "      <td>0.552484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.041140e-01</td>\n",
       "      <td>-1.239610</td>\n",
       "      <td>1.334622e+00</td>\n",
       "      <td>0.528938</td>\n",
       "      <td>-0.353723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.107725</td>\n",
       "      <td>2.135539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-2.583552e-01</td>\n",
       "      <td>0.219082</td>\n",
       "      <td>-4.047055e-01</td>\n",
       "      <td>-0.219259</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>-0.379509</td>\n",
       "      <td>0.216459</td>\n",
       "      <td>-0.525067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_4  feature_5    feature_13  feature_16  feature_18  feature_19  \\\n",
       "0   6.815085e-01   1.241897  6.025191e-02    2.989976    0.586640    2.825037   \n",
       "1   2.333640e-02   0.028713  1.204098e+00    1.441944   -0.282662    1.621808   \n",
       "2  -1.429926e+00   0.453171  6.791818e-01   -0.212485    0.744652   -0.191386   \n",
       "3  -1.106776e+00  -0.373329  2.432158e-02   -0.163841    1.107297   -0.163787   \n",
       "4  -8.042431e-01   0.630557 -1.352646e+00   -0.281485   -0.142565   -0.132747   \n",
       "5   6.895844e-01  -2.543375 -1.142840e-01    0.433445    0.381975    0.545432   \n",
       "6   3.810513e-01   0.674661 -8.483148e-02   -0.194581   -1.183585    0.035786   \n",
       "7   5.169219e-01   0.463835 -7.263109e-16   -1.566104    0.000000   -1.679087   \n",
       "8  -7.753464e-01  -0.304909 -1.048743e+00   -1.222277   -0.944183   -1.011368   \n",
       "9   5.420221e-01   1.165831 -4.838873e-01    0.671211   -2.470490    0.364440   \n",
       "10 -5.594752e-01   0.267374 -1.784036e-01    1.116031   -0.376112    1.313307   \n",
       "11  1.585221e+00   0.322494  9.209983e-01    0.974761    0.893413    0.799519   \n",
       "12 -4.866166e-01  -0.562609  2.749321e-01   -1.964049   -0.270681   -1.747577   \n",
       "13  1.524773e-15  -0.027909 -1.653222e+00    0.689152    1.437153    0.607050   \n",
       "14 -1.573425e+00   0.331696  1.204186e+00   -0.177367   -0.172725    0.161767   \n",
       "15  9.235535e-01   1.929713 -1.020575e+00    0.031763   -1.103483   -0.002315   \n",
       "16 -5.968800e-01  -1.301626 -7.263109e-16    1.529211   -0.708396    1.464723   \n",
       "17 -1.830422e+00  -0.902329  1.000947e-02    2.107834   -0.563656    2.150856   \n",
       "18  3.041140e-01  -1.239610  1.334622e+00    0.528938   -0.353723    0.000000   \n",
       "19 -2.583552e-01   0.219082 -4.047055e-01   -0.219259    0.224242   -0.379509   \n",
       "\n",
       "    feature_20  feature_21  \n",
       "0    -0.212562   -0.742305  \n",
       "1    -1.030697    0.572066  \n",
       "2    -0.690297    0.097709  \n",
       "3    -0.181789    0.089097  \n",
       "4     1.359871   -1.244967  \n",
       "5    -0.059528    0.000000  \n",
       "6    -0.085991   -0.490201  \n",
       "7     2.078106   -1.529837  \n",
       "8     0.945145   -0.787615  \n",
       "9     0.296793   -1.063603  \n",
       "10   -0.000984   -0.373375  \n",
       "11   -0.853571    0.232804  \n",
       "12   -0.389026    0.400345  \n",
       "13    1.827744   -1.083627  \n",
       "14   -1.030749    0.483975  \n",
       "15    0.909294   -1.498954  \n",
       "16    0.920463    0.223249  \n",
       "17   -0.169427    0.552484  \n",
       "18   -1.107725    2.135539  \n",
       "19    0.216459   -0.525067  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#стандартизация\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "data_std = pd.DataFrame(std_scaler.fit_transform(data), index=data.index, columns=data.columns)\n",
    "data_std = data_std[['feature_4','feature_5','feature_13','feature_16','feature_18','feature_19','feature_20','feature_21']]\n",
    "target = data['target'] #столбец целевой переменной готов\n",
    "data_std.head(20)  #матрица признаков готова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b7369",
   "metadata": {},
   "source": [
    "# **Линейная регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf266d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Метрики      R2        MAE    MAPE %          MSE\n",
      "0  Значения  0.9352  79.134418  2.211308  10585.95485\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    y_pred = linear_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "d = {'Метрики': ['Значения'], \n",
    "     'R2': statistics.mean(R2_list),\n",
    "     'MAE': statistics.mean(MAE_list),\n",
    "     'MAPE %': statistics.mean(MAPE_list)*100,\n",
    "     'MSE': statistics.mean(MSE_list) } \n",
    "metrics_lin = pd.DataFrame(d)\n",
    "print(metrics_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f6891",
   "metadata": {},
   "source": [
    "# **Решающее дерево**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59bfed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Метрики       R2         MAE    MAPE %           MSE\n",
      "0  Значения  0.79917  140.765063  3.913686  32537.584814\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    tree_model = DecisionTreeRegressor()\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    y_pred=tree_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "d = {'Метрики': ['Значения'], \n",
    "     'R2': statistics.mean(R2_list),\n",
    "     'MAE': statistics.mean(MAE_list),\n",
    "     'MAPE %': statistics.mean(MAPE_list)*100,\n",
    "     'MSE': statistics.mean(MSE_list) } \n",
    "metrics_tree = pd.DataFrame(d)\n",
    "print(metrics_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3cf1a2",
   "metadata": {},
   "source": [
    "## *Найдем оптимальные гиперпараметры с помощью Optuna*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826c23d",
   "metadata": {},
   "source": [
    "### Максимальная глубина дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2a163319",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая глубина дерева:  11\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAPE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    depth = trial.suggest_int('depth', 1, 100)\n",
    "    mape_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        tree_model = DecisionTreeRegressor(max_depth=depth)\n",
    "        tree_model.fit(X_train, y_train)\n",
    "        y_pred = tree_model.predict(X_test)\n",
    "        mape_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    mape = statistics.mean(mape_list)\n",
    "    return mape\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_depth = study.best_params['depth']\n",
    "print('Лучшая глубина дерева: ', best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cc3be40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая глубина дерева:  10\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем r2\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    depth = trial.suggest_int('depth', 1, 100)\n",
    "    r2_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        tree_model = DecisionTreeRegressor(max_depth=depth)\n",
    "        tree_model.fit(X_train, y_train)\n",
    "        y_pred = tree_model.predict(X_test)\n",
    "        r2_list.append(r2_score(y_test, y_pred))\n",
    "    r2 = statistics.mean(r2_list)\n",
    "    return r2\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_depth = study.best_params['depth']\n",
    "print('Лучшая глубина дерева: ', best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d85fc31c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая глубина дерева:  11\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    depth = trial.suggest_int('depth', 1, 100)\n",
    "    MAE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        tree_model = DecisionTreeRegressor(max_depth=depth)\n",
    "        tree_model.fit(X_train, y_train)\n",
    "        y_pred = tree_model.predict(X_test)\n",
    "        MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAE = statistics.mean(MAE_list)\n",
    "    return MAE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_depth = study.best_params['depth']\n",
    "print('Лучшая глубина дерева: ', best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e299d7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая глубина дерева:  91\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MSE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    depth = trial.suggest_int('depth', 1, 100)\n",
    "    MSE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        tree_model = DecisionTreeRegressor(max_depth=depth)\n",
    "        tree_model.fit(X_train, y_train)\n",
    "        y_pred = tree_model.predict(X_test)\n",
    "        MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    MSE = statistics.mean(MSE_list)\n",
    "    return MSE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_depth = study.best_params['depth']\n",
    "print('Лучшая глубина дерева: ', best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e51d9",
   "metadata": {},
   "source": [
    "### Минимальное число элементов в листе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "751c8ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее минимальное число элементов в листе:  7\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAPE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    msl = trial.suggest_int('msl', 1, 100)\n",
    "    mape_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        tree_model = DecisionTreeRegressor(min_samples_leaf=msl)\n",
    "        tree_model.fit(X_train, y_train)\n",
    "        y_pred = tree_model.predict(X_test)\n",
    "        mape_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    mape = statistics.mean(mape_list)\n",
    "    return mape\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_msl = study.best_params['msl']\n",
    "print('Лучшее минимальное число элементов в листе: ', best_msl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4621b1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее минимальное число элементов в листе:  9\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем r2\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    msl = trial.suggest_int('msl', 1, 100)\n",
    "    r2_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        tree_model = DecisionTreeRegressor(min_samples_leaf=msl)\n",
    "        tree_model.fit(X_train, y_train)\n",
    "        y_pred = tree_model.predict(X_test)\n",
    "        r2_list.append(r2_score(y_test, y_pred))\n",
    "    r2 = statistics.mean(r2_list)\n",
    "    return r2\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_msl = study.best_params['msl']\n",
    "print('Лучшее минимальное число элементов в листе: ', best_msl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "af314653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее минимальное число элементов в листе:  7\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    msl = trial.suggest_int('msl', 1, 100)\n",
    "    MAE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        tree_model = DecisionTreeRegressor(min_samples_leaf=msl)\n",
    "        tree_model.fit(X_train, y_train)\n",
    "        y_pred = tree_model.predict(X_test)\n",
    "        MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAE = statistics.mean(MAE_list)\n",
    "    return MAE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_msl = study.best_params['msl']\n",
    "print('Лучшее минимальное число элементов в листе: ', best_msl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d6c58fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее минимальное число элементов в листе:  8\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MSE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    msl = trial.suggest_int('msl', 1, 100)\n",
    "    MSE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        tree_model = DecisionTreeRegressor(min_samples_leaf=msl)\n",
    "        tree_model.fit(X_train, y_train)\n",
    "        y_pred = tree_model.predict(X_test)\n",
    "        MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    MSE = statistics.mean(MSE_list)\n",
    "    return MSE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_msl = study.best_params['msl']\n",
    "print('Лучшее минимальное число элементов в листе: ', best_msl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9089d1",
   "metadata": {},
   "source": [
    "*Проверим решающее дерево с тремя наборами гиперпараметров:*\n",
    "1. max_depth, min_samples_leaf - стандартные\n",
    "2. max_depth = 11, min_samples_leaf = 8 \n",
    "3. max_depth = 91, min_samples_leaf = 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "216f76f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Гиперпараметры        R2         MAE    MAPE %           MSE\n",
      "0         Стандартные  0.802496  141.295052  3.929775  32336.991358\n",
      "1  max_depth=11,msl=8  0.832318  129.081036  3.590431  27108.396118\n",
      "2  max_depth=91,msl=8  0.840255  127.313442  3.540213  26253.097187\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    tree_model = DecisionTreeRegressor()\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    y_pred=tree_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "r2_1 = statistics.mean(R2_list)\n",
    "MAE_1 = statistics.mean(MAE_list)\n",
    "MAPE_1 = statistics.mean(MAPE_list)*100\n",
    "MSE_1 = statistics.mean(MSE_list)\n",
    "\n",
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    tree_model = DecisionTreeRegressor(max_depth = 11,min_samples_leaf = 8)\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    y_pred=tree_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "r2_2 = statistics.mean(R2_list)\n",
    "MAE_2 = statistics.mean(MAE_list)\n",
    "MAPE_2 = statistics.mean(MAPE_list)*100\n",
    "MSE_2 = statistics.mean(MSE_list)\n",
    "\n",
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    tree_model = DecisionTreeRegressor(max_depth = 91,min_samples_leaf = 8)\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    y_pred=tree_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "r2_3 = statistics.mean(R2_list)\n",
    "MAE_3 = statistics.mean(MAE_list)\n",
    "MAPE_3 = statistics.mean(MAPE_list)*100\n",
    "MSE_3 = statistics.mean(MSE_list)\n",
    "    \n",
    "d = {'Гиперпараметры': ['Стандартные','max_depth=11,msl=8','max_depth=91,msl=8'], \n",
    "     'R2': [r2_1,r2_2,r2_3],\n",
    "     'MAE': [MAE_1,MAE_2,MAE_3],\n",
    "     'MAPE %': [MAPE_1,MAPE_2,MAPE_3],\n",
    "     'MSE': [MSE_1,MSE_2,MSE_3] } \n",
    "metrics_tree_opt = pd.DataFrame(d)\n",
    "print(metrics_tree_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8cb78",
   "metadata": {},
   "source": [
    "Оптимальные параметры для решающего дерева - max_depth = 91, min_samples_leaf = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc106c83",
   "metadata": {},
   "source": [
    "# **Алгоритм KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7422e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Метрики       R2         MAE    MAPE %           MSE\n",
      "0  Значения  0.89496  102.089285  2.846368  17254.122495\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    knn_model = KNeighborsRegressor()\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "d = {'Метрики': ['Значения'], \n",
    "     'R2': statistics.mean(R2_list),\n",
    "     'MAE': statistics.mean(MAE_list),\n",
    "     'MAPE %': statistics.mean(MAPE_list)*100,\n",
    "     'MSE': statistics.mean(MSE_list) } \n",
    "metrics_knn = pd.DataFrame(d)\n",
    "print(metrics_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23954caf",
   "metadata": {},
   "source": [
    "## *Найдем оптимальные гиперпараметры с помощью Optuna*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfecbefc",
   "metadata": {},
   "source": [
    "### Число соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "663429b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее число соседей:  10\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAPE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 100)\n",
    "    mape_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        mape_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    mape = statistics.mean(mape_list)\n",
    "    return mape\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_n = study.best_params['n_neighbors']\n",
    "print('Лучшее число соседей: ', best_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ab22ae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее число соседей:  11\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем r2\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 100)\n",
    "    r2_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        r2_list.append(r2_score(y_test, y_pred))\n",
    "    r2 = statistics.mean(r2_list)\n",
    "    return r2\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_n = study.best_params['n_neighbors']\n",
    "print('Лучшее число соседей: ', best_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3a9eb7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее число соседей:  13\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 100)\n",
    "    MAE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAE = statistics.mean(MAE_list)\n",
    "    return MAE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_n = study.best_params['n_neighbors']\n",
    "print('Лучшее число соседей: ', best_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "26de136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее число соседей:  12\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MSE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 100)\n",
    "    MSE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    MSE = statistics.mean(MSE_list)\n",
    "    return MSE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_n = study.best_params['n_neighbors']\n",
    "print('Лучшее число соседей: ', best_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5995998",
   "metadata": {},
   "source": [
    "### Метод определения расстояния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f261abba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший метод определения расстояния:  minkowski\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAPE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    metric = trial.suggest_categorical('metric', ['minkowski','euclidean','manhattan','chebyshev'])\n",
    "    mape_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(metric=metric)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        mape_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    mape = statistics.mean(mape_list)\n",
    "    return mape\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_metric = study.best_params['metric']\n",
    "print('Лучший метод определения расстояния: ', best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c7974eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший метод определения расстояния:  euclidean\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем r2\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    metric = trial.suggest_categorical('metric', ['minkowski','euclidean','manhattan','chebyshev'])\n",
    "    r2_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(metric=metric)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        r2_list.append(r2_score(y_test, y_pred))\n",
    "    r2 = statistics.mean(r2_list)\n",
    "    return r2\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_metric = study.best_params['metric']\n",
    "print('Лучший метод определения расстояния: ', best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4bc85142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший метод определения расстояния:  euclidean\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    metric = trial.suggest_categorical('metric', ['minkowski','euclidean','manhattan','chebyshev'])\n",
    "    MAE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(metric=metric)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAE = statistics.mean(MAE_list)\n",
    "    return MAE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_metric = study.best_params['metric']\n",
    "print('Лучший метод определения расстояния: ', best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "45f090e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший метод определения расстояния:  minkowski\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MSE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    metric = trial.suggest_categorical('metric', ['minkowski','euclidean','manhattan','chebyshev'])\n",
    "    MSE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(metric=metric)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    MSE = statistics.mean(MSE_list)\n",
    "    return MSE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_metric = study.best_params['metric']\n",
    "print('Лучший метод определения расстояния: ', best_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1e954",
   "metadata": {},
   "source": [
    "### степень p для определения расстояния Минковского"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9b55498",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая степень p:  2\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAPE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    p = trial.suggest_int('p', 1, 100)\n",
    "    mape_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(metric='minkowski', p = p)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        mape_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    mape = statistics.mean(mape_list)\n",
    "    return mape\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_p = study.best_params['p']\n",
    "print('Лучшая степень p: ', best_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fe8c5831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая степень p:  4\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем r2\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    p = trial.suggest_int('p', 1, 100)\n",
    "    r2_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(metric='minkowski', p = p)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        r2_list.append(r2_score(y_test, y_pred))\n",
    "    r2 = statistics.mean(r2_list)\n",
    "    return r2\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_p = study.best_params['p']\n",
    "print('Лучшая степень p: ', best_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bf70eac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая степень p:  3\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    p = trial.suggest_int('p', 1, 100)\n",
    "    MAE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(metric='minkowski', p = p)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAE = statistics.mean(MAE_list)\n",
    "    return MAE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_p = study.best_params['p']\n",
    "print('Лучшая степень p: ', best_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c7555b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая степень p:  3\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MSE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    p = trial.suggest_int('p', 1, 100)\n",
    "    MSE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        knn_model = KNeighborsRegressor(metric='minkowski', p = p)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    MSE = statistics.mean(MSE_list)\n",
    "    return MSE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_p = study.best_params['p']\n",
    "print('Лучшая степень p: ', best_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef48cc06",
   "metadata": {},
   "source": [
    "*Проверим алгоритм KNN с пятью наборами гиперпараметров:*\n",
    "1. Число соседей, Метод определения расстояния - стандартные\n",
    "2. число соседей = 12, Метод определения расстояния = minkowski \n",
    "3. число соседей = 12, Метод определения расстояния = euclidean \n",
    "4. число соседей = 12, Метод определения расстояния = minkowski, степень p = 3\n",
    "5. число соседей = 12, Метод определения расстояния = minkowski, степень p = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0d04da28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Гиперпараметры        R2         MAE    MAPE %           MSE\n",
      "0         Стандартные  0.898057  100.929191  2.817589  16492.687545\n",
      "1      n=12,minkowski  0.901505   98.717634  2.752640  16164.623961\n",
      "2      n=12,euclidean  0.902407   98.762311  2.775038  16066.976164\n",
      "3  n=12,minkowski p=3  0.903041   97.821607  2.735068  15904.331911\n",
      "4  n=12,minkowski p=4  0.899419   99.461131  2.770747  16518.025172\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    knn_model = KNeighborsRegressor()\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "r2_1 = statistics.mean(R2_list)\n",
    "MAE_1 = statistics.mean(MAE_list)\n",
    "MAPE_1 = statistics.mean(MAPE_list)*100\n",
    "MSE_1 = statistics.mean(MSE_list)\n",
    "\n",
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=12, metric = 'minkowski')\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "r2_2 = statistics.mean(R2_list)\n",
    "MAE_2 = statistics.mean(MAE_list)\n",
    "MAPE_2 = statistics.mean(MAPE_list)*100\n",
    "MSE_2 = statistics.mean(MSE_list)\n",
    "\n",
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=12, metric = 'euclidean')\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "r2_3 = statistics.mean(R2_list)\n",
    "MAE_3 = statistics.mean(MAE_list)\n",
    "MAPE_3 = statistics.mean(MAPE_list)*100\n",
    "MSE_3 = statistics.mean(MSE_list)\n",
    "\n",
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=12, metric = 'minkowski', p = 3)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "r2_4 = statistics.mean(R2_list)\n",
    "MAE_4 = statistics.mean(MAE_list)\n",
    "MAPE_4 = statistics.mean(MAPE_list)*100\n",
    "MSE_4= statistics.mean(MSE_list)\n",
    "\n",
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=12, metric = 'minkowski', p = 4)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "r2_5= statistics.mean(R2_list)\n",
    "MAE_5= statistics.mean(MAE_list)\n",
    "MAPE_5= statistics.mean(MAPE_list)*100\n",
    "MSE_5= statistics.mean(MSE_list)\n",
    "                                    \n",
    "d = {'Гиперпараметры': ['Стандартные','n=12,minkowski','n=12,euclidean','n=12,minkowski p=3','n=12,minkowski p=4'], \n",
    "     'R2': [r2_1,r2_2,r2_3,r2_4,r2_5],\n",
    "     'MAE': [MAE_1,MAE_2,MAE_3,MAE_4,MAE_5],\n",
    "     'MAPE %': [MAPE_1,MAPE_2,MAPE_3,MAPE_4,MAPE_5],\n",
    "     'MSE': [MSE_1,MSE_2,MSE_3,MSE_4,MSE_5] } \n",
    "metrics_KNN_opt = pd.DataFrame(d)\n",
    "print(metrics_KNN_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d9112f",
   "metadata": {},
   "source": [
    "Оптимальные параметры для алгоритма KNN - n_neighbors=12, metric = 'minkowski', p = 4   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c2bb7",
   "metadata": {},
   "source": [
    "# **Случайный лес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8bcf9dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Метрики        R2        MAE    MAPE %           MSE\n",
      "0  Значения  0.915555  91.987102  2.562526  13891.205933\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    random_forest = RandomForestRegressor()\n",
    "    random_forest.fit(X_train, y_train)\n",
    "    y_pred = random_forest.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "d = {'Метрики': ['Значения'], \n",
    "     'R2': statistics.mean(R2_list),\n",
    "     'MAE': statistics.mean(MAE_list),\n",
    "     'MAPE %': statistics.mean(MAPE_list)*100,\n",
    "     'MSE': statistics.mean(MSE_list) } \n",
    "metrics_rf = pd.DataFrame(d)\n",
    "print(metrics_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b4f60",
   "metadata": {},
   "source": [
    "## *Найдем оптимальные гиперпараметры с помощью Optuna*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb365a89",
   "metadata": {},
   "source": [
    "### Число моделей в ансамбле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d850eed8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее число моделей в ансамбле:  120\n",
      "время выполнения в секундах:  2518.8406801223755\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAPE\n",
    "start_time = time.time()\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 80, 120)\n",
    "    mape_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        random_forest = RandomForestRegressor(n_estimators=n_estimators)\n",
    "        random_forest.fit(X_train, y_train)\n",
    "        y_pred = random_forest.predict(X_test)\n",
    "        mape_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    mape = statistics.mean(mape_list)\n",
    "    return mape\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_n_estimators = study.best_params['n_estimators']\n",
    "print('Лучшее число моделей в ансамбле: ', best_n_estimators)\n",
    "print('время выполнения в секундах: ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b375cf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее число моделей в ансамбле:  108\n",
      "время выполнения в секундах:  2413.499922990799\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем r2\n",
    "start_time = time.time()\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 80, 120)\n",
    "    r2_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        random_forest = RandomForestRegressor(n_estimators=n_estimators)\n",
    "        random_forest.fit(X_train, y_train)\n",
    "        y_pred = random_forest.predict(X_test)\n",
    "        r2_list.append(r2_score(y_test, y_pred))\n",
    "    r2 = statistics.mean(r2_list)\n",
    "    return r2\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_n_estimators = study.best_params['n_estimators']\n",
    "print('Лучшее число моделей в ансамбле: ', best_n_estimators)\n",
    "print('время выполнения в секундах: ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "406f7ae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее число моделей в ансамбле:  109\n",
      "время выполнения в секундах:  2450.838552236557\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MAE\n",
    "start_time = time.time()\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 80, 120)\n",
    "    MAE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        random_forest = RandomForestRegressor(n_estimators=n_estimators)\n",
    "        random_forest.fit(X_train, y_train)\n",
    "        y_pred = random_forest.predict(X_test)\n",
    "        MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAE = statistics.mean(MAE_list)\n",
    "    return MAE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_n_estimators = study.best_params['n_estimators']\n",
    "print('Лучшее число моделей в ансамбле: ', best_n_estimators)\n",
    "print('время выполнения в секундах: ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c818dbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее число моделей в ансамбле:  105\n",
      "время выполнения в секундах:  2449.5079305171967\n"
     ]
    }
   ],
   "source": [
    "#в качестве целевой метрики выберем MSE\n",
    "start_time = time.time()\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 80, 120)\n",
    "    MSE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        random_forest = RandomForestRegressor(n_estimators=n_estimators)\n",
    "        random_forest.fit(X_train, y_train)\n",
    "        y_pred = random_forest.predict(X_test)\n",
    "        MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    MSE = statistics.mean(MSE_list)\n",
    "    return MSE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_n_estimators = study.best_params['n_estimators']\n",
    "print('Лучшее число моделей в ансамбле: ', best_n_estimators)\n",
    "print('время выполнения в секундах: ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafaf2fe",
   "metadata": {},
   "source": [
    "**Нетрудно видеть, что подбор оптимальных гиперпараметров для случайного леса занимает много времени. Подбирать другие гиперпараметры я не буду, так как впринципи не планирую использовать случайный лес - мне он не нравится**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d39461",
   "metadata": {},
   "source": [
    "# **Градиентный бустинг**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac910516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Метрики        R2       MAE    MAPE %           MSE\n",
      "0  Значения  0.924518  86.21422  2.399834  12279.269742\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    grad_boost = GradientBoostingRegressor()\n",
    "    grad_boost.fit(X_train, y_train)\n",
    "    y_pred = grad_boost.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "d = {'Метрики': ['Значения'], \n",
    "     'R2': statistics.mean(R2_list),\n",
    "     'MAE': statistics.mean(MAE_list),\n",
    "     'MAPE %': statistics.mean(MAPE_list)*100,\n",
    "     'MSE': statistics.mean(MSE_list) } \n",
    "metrics_gb = pd.DataFrame(d)\n",
    "print(metrics_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749177bb",
   "metadata": {},
   "source": [
    "### Число моделей в ансамбле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e75a28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#в качестве целевой метрики выберем MAPE\n",
    "start_time = time.time()\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 80, 120)\n",
    "    mape_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        grad_boost = GradientBoostingRegressor(n_estimators=n_estimators)\n",
    "        grad_boost.fit(X_train, y_train)\n",
    "        y_pred = grad_boost.predict(X_test)\n",
    "        mape_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    mape = statistics.mean(mape_list)\n",
    "    return mape\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_n_estimators = study.best_params['n_estimators']\n",
    "print('Лучшее число моделей в ансамбле: ', best_n_estimators)\n",
    "print('время выполнения в секундах: ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927287e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#в качестве целевой метрики выберем r2\n",
    "start_time = time.time()\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 80, 120)\n",
    "    r2_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        grad_boost = GradientBoostingRegressor(n_estimators=n_estimators)\n",
    "        grad_boost.fit(X_train, y_train)\n",
    "        y_pred = grad_boost.predict(X_test)\n",
    "        r2_list.append(r2_score(y_test, y_pred))\n",
    "    r2 = statistics.mean(r2_list)\n",
    "    return r2\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_n_estimators = study.best_params['n_estimators']\n",
    "print('Лучшее число моделей в ансамбле: ', best_n_estimators)\n",
    "print('время выполнения в секундах: ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799abd64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#в качестве целевой метрики выберем MAE\n",
    "start_time = time.time()\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 80, 120)\n",
    "    MAE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        grad_boost = GradientBoostingRegressor(n_estimators=n_estimators)\n",
    "        grad_boost.fit(X_train, y_train)\n",
    "        y_pred = grad_boost.predict(X_test)\n",
    "        MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAE = statistics.mean(MAE_list)\n",
    "    return MAE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_n_estimators = study.best_params['n_estimators']\n",
    "print('Лучшее число моделей в ансамбле: ', best_n_estimators)\n",
    "print('время выполнения в секундах: ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36db651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#в качестве целевой метрики выберем MSE\n",
    "start_time = time.time()\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 80, 120)\n",
    "    MSE_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        grad_boost = GradientBoostingRegressor(n_estimators=n_estimators)\n",
    "        grad_boost.fit(X_train, y_train)\n",
    "        y_pred = grad_boost.predict(X_test)\n",
    "        MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    MSE = statistics.mean(MSE_list)\n",
    "    return MSE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_n_estimators = study.best_params['n_estimators']\n",
    "print('Лучшее число моделей в ансамбле: ', best_n_estimators)\n",
    "print('время выполнения в секундах: ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af86cd",
   "metadata": {},
   "source": [
    "**Аналогично лесу, не будем оптимизировать гиперпараметры из-за недостатка времени. Будем сравнивать с другими моделями на стандартных гиперпараметрах**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59529097",
   "metadata": {},
   "source": [
    "# **Алгоритм SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01292305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Метрики        R2         MAE   MAPE %           MSE\n",
      "0  Значения  0.649899  168.519384  4.76385  56882.206259\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    svm_model = svm.SVR()\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "d = {'Метрики': ['Значения'], \n",
    "     'R2': statistics.mean(R2_list),\n",
    "     'MAE': statistics.mean(MAE_list),\n",
    "     'MAPE %': statistics.mean(MAPE_list)*100,\n",
    "     'MSE': statistics.mean(MSE_list) } \n",
    "metrics_svm = pd.DataFrame(d)\n",
    "print(metrics_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6555cee7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#в качестве целевой метрики выберем MAPE\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) #убирает промежуточные выводы в консоль\n",
    "def objective(trial):\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'])\n",
    "    mape_list = []\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        svm_model = svm.SVR()\n",
    "        svm_model.fit(X_train, y_train)\n",
    "        y_pred = svm_model.predict(X_test)\n",
    "        mape_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    mape = statistics.mean(mape_list)\n",
    "    return mape\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_kernel = study.best_params['kernel']\n",
    "print('Лучший параметр kernel: ', best_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b788f",
   "metadata": {},
   "source": [
    "**Аналогично , не будем оптимизировать гиперпараметры из-за недостатка времени. Будем сравнивать с другими моделями на стандартных гиперпараметрах**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861068ec",
   "metadata": {},
   "source": [
    "# **Cat Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef96e066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Метрики        R2        MAE    MAPE %           MSE\n",
      "0  Значения  0.936763  79.680445  2.213235  10255.285187\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    model_cat = CatBoostRegressor(verbose=False)\n",
    "    model_cat.fit(X_train, y_train)\n",
    "    y_pred = model_cat.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "d = {'Метрики': ['Значения'], \n",
    "     'R2': statistics.mean(R2_list),\n",
    "     'MAE': statistics.mean(MAE_list),\n",
    "     'MAPE %': statistics.mean(MAPE_list)*100,\n",
    "     'MSE': statistics.mean(MSE_list) } \n",
    "metrics_cat = pd.DataFrame(d)\n",
    "print(metrics_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a98e29",
   "metadata": {},
   "source": [
    "**Исходя из опыта предыдущих домашних заданий, CatBoost мне нравится больше всего, поэтому я буду использовать скорее всего именно его. Однако ради честности мы проверим и другие известные нам модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18117332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'iterations': 266, 'depth': 4, 'learning_rate': 0.2707359937386986, 'random_strength': 8, 'bagging_temperature': 0.3359766704210055, 'od_type': 'Iter'}\n",
      "Лучшая mape: 0.021794765232808273\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 300),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_strength': trial.suggest_int('random_strength', 0, 100),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter'])\n",
    "    }\n",
    "    mape_list = []\n",
    "    for i in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        model = CatBoostRegressor(**param, verbose=False) #распаковка словаря\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        mape_list.append(mape)\n",
    "    return np.mean(mape_list)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "params = study.best_params\n",
    "\n",
    "print('Лучшие параметры:', study.best_params)\n",
    "print('Лучшая mape:', study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6787a",
   "metadata": {},
   "source": [
    "# **LGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecb50f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Метрики       R2        MAE    MAPE %           MSE\n",
      "0  Значения  0.92762  84.806427  2.365531  11727.860972\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    model_lgbm = LGBMRegressor(verbose=-1)\n",
    "    model_lgbm.fit(X_train, y_train)\n",
    "    y_pred = model_lgbm.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "d = {'Метрики': ['Значения'], \n",
    "     'R2': statistics.mean(R2_list),\n",
    "     'MAE': statistics.mean(MAE_list),\n",
    "     'MAPE %': statistics.mean(MAPE_list)*100,\n",
    "     'MSE': statistics.mean(MSE_list) } \n",
    "metrics_lgbm = pd.DataFrame(d)\n",
    "print(metrics_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f632b4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для LGBMRegressor: {'n_estimators': 285, 'max_depth': 4, 'learning_rate': 0.0667800617492735, 'num_leaves': 45, 'feature_fraction': 0.5912976230111192, 'bagging_fraction': 0.7784209266670588, 'bagging_freq': 5}\n",
      "Лучшее mape для LGBMRegressor: 0.02254435489867177\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 200),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7)\n",
    "    }\n",
    "    mape_list = []\n",
    "    for i in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        model = LGBMRegressor(**param, verbose=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        mape_list.append(mape)\n",
    "    return np.mean(mape_list)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Лучшие параметры для LGBMRegressor:', study.best_params)\n",
    "print('Лучшее mape для LGBMRegressor:', study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd0990",
   "metadata": {},
   "source": [
    "# **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2da15231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Метрики        R2        MAE    MAPE %           MSE\n",
      "0  Значения  0.915605  92.480153  2.572713  13802.528164\n"
     ]
    }
   ],
   "source": [
    "MSE_list = []\n",
    "MAE_list = []\n",
    "R2_list = []\n",
    "MAPE_list = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    model_xg = XGBRegressor(verbosity=0)\n",
    "    model_xg.fit(X_train, y_train)\n",
    "    y_pred = model_xg.predict(X_test)\n",
    "    MSE_list.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_list.append(r2_score(y_test, y_pred))\n",
    "    MAE_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "d = {'Метрики': ['Значения'], \n",
    "     'R2': statistics.mean(R2_list),\n",
    "     'MAE': statistics.mean(MAE_list),\n",
    "     'MAPE %': statistics.mean(MAPE_list)*100,\n",
    "     'MSE': statistics.mean(MSE_list) } \n",
    "metrics_xg = pd.DataFrame(d)\n",
    "print(metrics_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2c0c7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для XGBRegressor: {'n_estimators': 290, 'max_depth': 5, 'learning_rate': 0.04217362603862221, 'min_child_weight': 9, 'colsample_bytree': 0.547670028024333, 'subsample': 0.6578462722681467, 'gamma': 3.3020020562272867}\n",
      "Лучшее mape для XGBRegressor: 0.022435695578012553\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5)\n",
    "    }\n",
    "    mape_list = []\n",
    "    for i in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "        model = XGBRegressor(**param, verbosity=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        mape_list.append(mape)\n",
    "    return np.mean(mape_list)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Лучшие параметры для XGBRegressor:', study.best_params)\n",
    "print('Лучшее mape для XGBRegressor:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71c6cc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "стандартные гиперпараметры: [0.021905909691066566, 0.02269533845183049, 0.022043007512778, 0.022776274300573385, 0.02212829531638746, 0.022806833739487855, 0.02183474334150852, 0.02250610170889984, 0.022378903569607225, 0.021445352029272315]\n",
      "оптимальные гиперпараметры: [0.022089556427625123, 0.02204166957003413, 0.022937927163685288, 0.022005305930353453, 0.02230717294001661, 0.02243694606027403, 0.022059007223166824, 0.022543408835654314, 0.022663818684336475, 0.022345756553455328]\n",
      "t-статистика: -0.523311936282237, p-значение: 0.6071402247973989\n",
      "Нет разницы.\n"
     ]
    }
   ],
   "source": [
    "MAPE_list_st = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    model_cat = CatBoostRegressor(verbose=False)\n",
    "    model_cat.fit(X_train, y_train)\n",
    "    y_pred = model_cat.predict(X_test)\n",
    "    MAPE_list_st.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    \n",
    "MAPE_list_opt = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "    model_cat = CatBoostRegressor(**params,verbose=False)\n",
    "    model_cat.fit(X_train, y_train)\n",
    "    y_pred = model_cat.predict(X_test)\n",
    "    MAPE_list_opt.append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "print('стандартные гиперпараметры:', MAPE_list_st)\n",
    "print('оптимальные гиперпараметры:', MAPE_list_opt)\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(MAPE_list_st, MAPE_list_opt)\n",
    "print(f\"t-статистика: {t_stat}, p-значение: {p_value}\")\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Есть улучшение.\")\n",
    "else:\n",
    "    print(\"Нет разницы.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0150d",
   "metadata": {},
   "source": [
    "# **Проверка на переобучение**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03a7178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE на обучающей выборке: 5780.9199889248885\n",
      "MSE на тестовой выборке: 9606.429942410314\n",
      "F-статистика: 0.39069443590578123, p-значение: 0.5319524345529311\n",
      "Дисперсии ошибок не различаются. Переобучение маловероятно.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_std, target, test_size=0.2)\n",
    "\n",
    "catboost_model = CatBoostRegressor(verbose=False)\n",
    "\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = catboost_model.predict(X_train)\n",
    "y_test_pred = catboost_model.predict(X_test)\n",
    "\n",
    "errors_train = y_train - y_train_pred\n",
    "errors_test = y_test - y_test_pred\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "f_stat, p_value = stats.f_oneway(errors_train, errors_test)\n",
    "\n",
    "print(f\"MSE на обучающей выборке: {mse_train}\")\n",
    "print(f\"MSE на тестовой выборке: {mse_test}\")\n",
    "print(f\"F-статистика: {f_stat}, p-значение: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Дисперсии ошибок статистически значимо различаются. Есть основания полагать переобучение.\")\n",
    "else:\n",
    "    print(\"Дисперсии ошибок не различаются. Переобучение маловероятно.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ccfea",
   "metadata": {},
   "source": [
    "### **Результат**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5a79d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>592.557499</td>\n",
       "      <td>1051.942183</td>\n",
       "      <td>567.481562</td>\n",
       "      <td>357.353602</td>\n",
       "      <td>659.307080</td>\n",
       "      <td>428.943493</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.608991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>557.883768</td>\n",
       "      <td>944.823942</td>\n",
       "      <td>316.514134</td>\n",
       "      <td>507.606088</td>\n",
       "      <td>804.842967</td>\n",
       "      <td>555.343815</td>\n",
       "      <td>1.014173</td>\n",
       "      <td>0.429736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>522.560548</td>\n",
       "      <td>1013.940987</td>\n",
       "      <td>558.239115</td>\n",
       "      <td>250.793462</td>\n",
       "      <td>807.260372</td>\n",
       "      <td>319.277907</td>\n",
       "      <td>0.575022</td>\n",
       "      <td>0.640453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524.953050</td>\n",
       "      <td>947.950969</td>\n",
       "      <td>446.784691</td>\n",
       "      <td>334.327243</td>\n",
       "      <td>749.708974</td>\n",
       "      <td>391.398992</td>\n",
       "      <td>0.718467</td>\n",
       "      <td>0.544028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638.678286</td>\n",
       "      <td>995.491884</td>\n",
       "      <td>575.743219</td>\n",
       "      <td>400.544035</td>\n",
       "      <td>779.329861</td>\n",
       "      <td>449.231423</td>\n",
       "      <td>0.557540</td>\n",
       "      <td>0.648378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>527.992309</td>\n",
       "      <td>1246.003508</td>\n",
       "      <td>445.720205</td>\n",
       "      <td>414.028527</td>\n",
       "      <td>773.442383</td>\n",
       "      <td>472.698450</td>\n",
       "      <td>0.720183</td>\n",
       "      <td>0.412302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>615.996084</td>\n",
       "      <td>837.451195</td>\n",
       "      <td>395.453534</td>\n",
       "      <td>426.580923</td>\n",
       "      <td>736.263784</td>\n",
       "      <td>499.471846</td>\n",
       "      <td>0.811726</td>\n",
       "      <td>0.552217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>569.822542</td>\n",
       "      <td>991.701515</td>\n",
       "      <td>557.635586</td>\n",
       "      <td>356.434188</td>\n",
       "      <td>746.241450</td>\n",
       "      <td>422.335567</td>\n",
       "      <td>0.575645</td>\n",
       "      <td>0.643868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>598.650048</td>\n",
       "      <td>993.631124</td>\n",
       "      <td>509.155877</td>\n",
       "      <td>243.712087</td>\n",
       "      <td>836.479496</td>\n",
       "      <td>296.325650</td>\n",
       "      <td>0.630455</td>\n",
       "      <td>0.583522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>519.228458</td>\n",
       "      <td>822.369846</td>\n",
       "      <td>402.678918</td>\n",
       "      <td>244.251659</td>\n",
       "      <td>736.010952</td>\n",
       "      <td>309.950857</td>\n",
       "      <td>0.797161</td>\n",
       "      <td>0.582378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>579.998993</td>\n",
       "      <td>838.950976</td>\n",
       "      <td>556.563483</td>\n",
       "      <td>326.416801</td>\n",
       "      <td>664.197375</td>\n",
       "      <td>401.474032</td>\n",
       "      <td>0.576754</td>\n",
       "      <td>0.749023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600.801881</td>\n",
       "      <td>847.810457</td>\n",
       "      <td>487.062235</td>\n",
       "      <td>363.163324</td>\n",
       "      <td>734.228993</td>\n",
       "      <td>428.270510</td>\n",
       "      <td>0.659053</td>\n",
       "      <td>0.669807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>621.327188</td>\n",
       "      <td>1045.911053</td>\n",
       "      <td>534.847129</td>\n",
       "      <td>278.834558</td>\n",
       "      <td>749.970667</td>\n",
       "      <td>352.246384</td>\n",
       "      <td>0.600171</td>\n",
       "      <td>0.575522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>497.581828</td>\n",
       "      <td>856.581521</td>\n",
       "      <td>488.471406</td>\n",
       "      <td>384.397585</td>\n",
       "      <td>669.457843</td>\n",
       "      <td>428.171962</td>\n",
       "      <td>0.657152</td>\n",
       "      <td>0.636027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>557.788341</td>\n",
       "      <td>1131.423902</td>\n",
       "      <td>470.971866</td>\n",
       "      <td>322.273591</td>\n",
       "      <td>824.608535</td>\n",
       "      <td>374.256317</td>\n",
       "      <td>0.681569</td>\n",
       "      <td>0.489329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>515.716060</td>\n",
       "      <td>1100.999026</td>\n",
       "      <td>510.956203</td>\n",
       "      <td>344.782870</td>\n",
       "      <td>765.986078</td>\n",
       "      <td>414.591584</td>\n",
       "      <td>0.628234</td>\n",
       "      <td>0.530834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>569.422752</td>\n",
       "      <td>1331.117796</td>\n",
       "      <td>424.218855</td>\n",
       "      <td>277.654868</td>\n",
       "      <td>757.510130</td>\n",
       "      <td>337.950642</td>\n",
       "      <td>0.756685</td>\n",
       "      <td>0.377898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>588.315397</td>\n",
       "      <td>932.640499</td>\n",
       "      <td>482.717809</td>\n",
       "      <td>306.372489</td>\n",
       "      <td>699.639043</td>\n",
       "      <td>362.637727</td>\n",
       "      <td>0.664985</td>\n",
       "      <td>0.595150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>455.747602</td>\n",
       "      <td>1130.167914</td>\n",
       "      <td>516.628276</td>\n",
       "      <td>338.493538</td>\n",
       "      <td>702.410551</td>\n",
       "      <td>402.752224</td>\n",
       "      <td>0.621336</td>\n",
       "      <td>0.511073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>592.983482</td>\n",
       "      <td>709.738929</td>\n",
       "      <td>451.362014</td>\n",
       "      <td>285.848513</td>\n",
       "      <td>653.146964</td>\n",
       "      <td>327.150486</td>\n",
       "      <td>0.711181</td>\n",
       "      <td>0.727407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_4    feature_5  feature_13  feature_16  feature_18  feature_19  \\\n",
       "0   592.557499  1051.942183  567.481562  357.353602  659.307080  428.943493   \n",
       "1   557.883768   944.823942  316.514134  507.606088  804.842967  555.343815   \n",
       "2   522.560548  1013.940987  558.239115  250.793462  807.260372  319.277907   \n",
       "3   524.953050   947.950969  446.784691  334.327243  749.708974  391.398992   \n",
       "4   638.678286   995.491884  575.743219  400.544035  779.329861  449.231423   \n",
       "5   527.992309  1246.003508  445.720205  414.028527  773.442383  472.698450   \n",
       "6   615.996084   837.451195  395.453534  426.580923  736.263784  499.471846   \n",
       "7   569.822542   991.701515  557.635586  356.434188  746.241450  422.335567   \n",
       "8   598.650048   993.631124  509.155877  243.712087  836.479496  296.325650   \n",
       "9   519.228458   822.369846  402.678918  244.251659  736.010952  309.950857   \n",
       "10  579.998993   838.950976  556.563483  326.416801  664.197375  401.474032   \n",
       "11  600.801881   847.810457  487.062235  363.163324  734.228993  428.270510   \n",
       "12  621.327188  1045.911053  534.847129  278.834558  749.970667  352.246384   \n",
       "13  497.581828   856.581521  488.471406  384.397585  669.457843  428.171962   \n",
       "14  557.788341  1131.423902  470.971866  322.273591  824.608535  374.256317   \n",
       "15  515.716060  1100.999026  510.956203  344.782870  765.986078  414.591584   \n",
       "16  569.422752  1331.117796  424.218855  277.654868  757.510130  337.950642   \n",
       "17  588.315397   932.640499  482.717809  306.372489  699.639043  362.637727   \n",
       "18  455.747602  1130.167914  516.628276  338.493538  702.410551  402.752224   \n",
       "19  592.983482   709.738929  451.362014  285.848513  653.146964  327.150486   \n",
       "\n",
       "    feature_20  feature_21  \n",
       "0     0.565657    0.608991  \n",
       "1     1.014173    0.429736  \n",
       "2     0.575022    0.640453  \n",
       "3     0.718467    0.544028  \n",
       "4     0.557540    0.648378  \n",
       "5     0.720183    0.412302  \n",
       "6     0.811726    0.552217  \n",
       "7     0.575645    0.643868  \n",
       "8     0.630455    0.583522  \n",
       "9     0.797161    0.582378  \n",
       "10    0.576754    0.749023  \n",
       "11    0.659053    0.669807  \n",
       "12    0.600171    0.575522  \n",
       "13    0.657152    0.636027  \n",
       "14    0.681569    0.489329  \n",
       "15    0.628234    0.530834  \n",
       "16    0.756685    0.377898  \n",
       "17    0.664985    0.595150  \n",
       "18    0.621336    0.511073  \n",
       "19    0.711181    0.727407  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('test-HW_BHW-sid_13.csv')\n",
    "important_features.remove('target')\n",
    "data_test = data_test[important_features]\n",
    "data_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e55c08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   feature_4   2000 non-null   float64\n",
      " 1   feature_5   2000 non-null   float64\n",
      " 2   feature_13  2000 non-null   float64\n",
      " 3   feature_16  2000 non-null   float64\n",
      " 4   feature_18  2000 non-null   float64\n",
      " 5   feature_19  2000 non-null   float64\n",
      " 6   feature_20  2000 non-null   float64\n",
      " 7   feature_21  2000 non-null   float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 125.1 KB\n"
     ]
    }
   ],
   "source": [
    "for column in important_features:\n",
    "    value = data_test[column].mean()\n",
    "    data_test[column].fillna(value,inplace=True)\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3f28fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719127</td>\n",
       "      <td>0.584269</td>\n",
       "      <td>1.304965</td>\n",
       "      <td>0.675880</td>\n",
       "      <td>-1.089974</td>\n",
       "      <td>0.919056</td>\n",
       "      <td>-1.120940</td>\n",
       "      <td>0.262399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255199</td>\n",
       "      <td>-0.124011</td>\n",
       "      <td>-1.982900</td>\n",
       "      <td>3.619507</td>\n",
       "      <td>1.213677</td>\n",
       "      <td>3.356290</td>\n",
       "      <td>2.453849</td>\n",
       "      <td>-1.111217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.217418</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>1.183882</td>\n",
       "      <td>-1.411762</td>\n",
       "      <td>1.251942</td>\n",
       "      <td>-1.195501</td>\n",
       "      <td>-1.046296</td>\n",
       "      <td>0.503487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.185407</td>\n",
       "      <td>-0.103335</td>\n",
       "      <td>-0.276256</td>\n",
       "      <td>0.224765</td>\n",
       "      <td>0.340975</td>\n",
       "      <td>0.195128</td>\n",
       "      <td>0.096995</td>\n",
       "      <td>-0.235410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.336214</td>\n",
       "      <td>0.211012</td>\n",
       "      <td>1.413199</td>\n",
       "      <td>1.522032</td>\n",
       "      <td>0.809837</td>\n",
       "      <td>1.310245</td>\n",
       "      <td>-1.185634</td>\n",
       "      <td>0.564217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.144743</td>\n",
       "      <td>1.867428</td>\n",
       "      <td>-0.290202</td>\n",
       "      <td>1.786210</td>\n",
       "      <td>0.716645</td>\n",
       "      <td>1.762733</td>\n",
       "      <td>0.110670</td>\n",
       "      <td>-1.244817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.032730</td>\n",
       "      <td>-0.833974</td>\n",
       "      <td>-0.948734</td>\n",
       "      <td>2.032127</td>\n",
       "      <td>0.128155</td>\n",
       "      <td>2.278974</td>\n",
       "      <td>0.840296</td>\n",
       "      <td>-0.172658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.414938</td>\n",
       "      <td>0.185949</td>\n",
       "      <td>1.175975</td>\n",
       "      <td>0.657867</td>\n",
       "      <td>0.286089</td>\n",
       "      <td>0.791643</td>\n",
       "      <td>-1.041336</td>\n",
       "      <td>0.529654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.800644</td>\n",
       "      <td>0.198708</td>\n",
       "      <td>0.540854</td>\n",
       "      <td>-1.550495</td>\n",
       "      <td>1.714444</td>\n",
       "      <td>-1.638064</td>\n",
       "      <td>-0.604482</td>\n",
       "      <td>0.067232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.262001</td>\n",
       "      <td>-0.933694</td>\n",
       "      <td>-0.854076</td>\n",
       "      <td>-1.539924</td>\n",
       "      <td>0.124153</td>\n",
       "      <td>-1.375344</td>\n",
       "      <td>0.724209</td>\n",
       "      <td>0.058466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.551097</td>\n",
       "      <td>-0.824057</td>\n",
       "      <td>1.161930</td>\n",
       "      <td>0.069790</td>\n",
       "      <td>-1.012567</td>\n",
       "      <td>0.389393</td>\n",
       "      <td>-1.032498</td>\n",
       "      <td>1.335446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.829435</td>\n",
       "      <td>-0.765477</td>\n",
       "      <td>0.251410</td>\n",
       "      <td>0.789699</td>\n",
       "      <td>0.095946</td>\n",
       "      <td>0.906079</td>\n",
       "      <td>-0.376547</td>\n",
       "      <td>0.728427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.104059</td>\n",
       "      <td>0.544390</td>\n",
       "      <td>0.877429</td>\n",
       "      <td>-0.862403</td>\n",
       "      <td>0.345117</td>\n",
       "      <td>-0.559808</td>\n",
       "      <td>-0.845851</td>\n",
       "      <td>0.005928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.551629</td>\n",
       "      <td>-0.707482</td>\n",
       "      <td>0.269871</td>\n",
       "      <td>1.205704</td>\n",
       "      <td>-0.929300</td>\n",
       "      <td>0.904179</td>\n",
       "      <td>-0.391701</td>\n",
       "      <td>0.469571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.253922</td>\n",
       "      <td>1.109812</td>\n",
       "      <td>0.040614</td>\n",
       "      <td>-0.011380</td>\n",
       "      <td>1.526542</td>\n",
       "      <td>-0.135415</td>\n",
       "      <td>-0.197088</td>\n",
       "      <td>-0.654566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.308996</td>\n",
       "      <td>0.908639</td>\n",
       "      <td>0.564440</td>\n",
       "      <td>0.429604</td>\n",
       "      <td>0.598621</td>\n",
       "      <td>0.642324</td>\n",
       "      <td>-0.622187</td>\n",
       "      <td>-0.336513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.409589</td>\n",
       "      <td>2.430214</td>\n",
       "      <td>-0.571886</td>\n",
       "      <td>-0.885515</td>\n",
       "      <td>0.464458</td>\n",
       "      <td>-0.835456</td>\n",
       "      <td>0.401602</td>\n",
       "      <td>-1.508449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.662368</td>\n",
       "      <td>-0.204570</td>\n",
       "      <td>0.194495</td>\n",
       "      <td>-0.322902</td>\n",
       "      <td>-0.451569</td>\n",
       "      <td>-0.359443</td>\n",
       "      <td>-0.329272</td>\n",
       "      <td>0.156337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.111362</td>\n",
       "      <td>1.101507</td>\n",
       "      <td>0.638748</td>\n",
       "      <td>0.306388</td>\n",
       "      <td>-0.407700</td>\n",
       "      <td>0.414039</td>\n",
       "      <td>-0.677161</td>\n",
       "      <td>-0.487942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.724826</td>\n",
       "      <td>-1.678424</td>\n",
       "      <td>-0.216290</td>\n",
       "      <td>-0.724991</td>\n",
       "      <td>-1.187481</td>\n",
       "      <td>-1.043703</td>\n",
       "      <td>0.038923</td>\n",
       "      <td>1.169807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_4  feature_5  feature_13  feature_16  feature_18  feature_19  \\\n",
       "0    0.719127   0.584269    1.304965    0.675880   -1.089974    0.919056   \n",
       "1    0.255199  -0.124011   -1.982900    3.619507    1.213677    3.356290   \n",
       "2   -0.217418   0.333000    1.183882   -1.411762    1.251942   -1.195501   \n",
       "3   -0.185407  -0.103335   -0.276256    0.224765    0.340975    0.195128   \n",
       "4    1.336214   0.211012    1.413199    1.522032    0.809837    1.310245   \n",
       "5   -0.144743   1.867428   -0.290202    1.786210    0.716645    1.762733   \n",
       "6    1.032730  -0.833974   -0.948734    2.032127    0.128155    2.278974   \n",
       "7    0.414938   0.185949    1.175975    0.657867    0.286089    0.791643   \n",
       "8    0.800644   0.198708    0.540854   -1.550495    1.714444   -1.638064   \n",
       "9   -0.262001  -0.933694   -0.854076   -1.539924    0.124153   -1.375344   \n",
       "10   0.551097  -0.824057    1.161930    0.069790   -1.012567    0.389393   \n",
       "11   0.829435  -0.765477    0.251410    0.789699    0.095946    0.906079   \n",
       "12   1.104059   0.544390    0.877429   -0.862403    0.345117   -0.559808   \n",
       "13  -0.551629  -0.707482    0.269871    1.205704   -0.929300    0.904179   \n",
       "14   0.253922   1.109812    0.040614   -0.011380    1.526542   -0.135415   \n",
       "15  -0.308996   0.908639    0.564440    0.429604    0.598621    0.642324   \n",
       "16   0.409589   2.430214   -0.571886   -0.885515    0.464458   -0.835456   \n",
       "17   0.662368  -0.204570    0.194495   -0.322902   -0.451569   -0.359443   \n",
       "18  -1.111362   1.101507    0.638748    0.306388   -0.407700    0.414039   \n",
       "19   0.724826  -1.678424   -0.216290   -0.724991   -1.187481   -1.043703   \n",
       "\n",
       "    feature_20  feature_21  \n",
       "0    -1.120940    0.262399  \n",
       "1     2.453849   -1.111217  \n",
       "2    -1.046296    0.503487  \n",
       "3     0.096995   -0.235410  \n",
       "4    -1.185634    0.564217  \n",
       "5     0.110670   -1.244817  \n",
       "6     0.840296   -0.172658  \n",
       "7    -1.041336    0.529654  \n",
       "8    -0.604482    0.067232  \n",
       "9     0.724209    0.058466  \n",
       "10   -1.032498    1.335446  \n",
       "11   -0.376547    0.728427  \n",
       "12   -0.845851    0.005928  \n",
       "13   -0.391701    0.469571  \n",
       "14   -0.197088   -0.654566  \n",
       "15   -0.622187   -0.336513  \n",
       "16    0.401602   -1.508449  \n",
       "17   -0.329272    0.156337  \n",
       "18   -0.677161   -0.487942  \n",
       "19    0.038923    1.169807  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler = preprocessing.StandardScaler()\n",
    "data_test_std = pd.DataFrame(std_scaler.fit_transform(data_test), index=data_test.index, columns=data_test.columns)\n",
    "data_test_std.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68d34690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3802.47186249 3450.92796237 3529.9530944  ... 3512.37970195 3802.46064525\n",
      " 3114.91270521]\n"
     ]
    }
   ],
   "source": [
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(data_std, target)\n",
    "predict = model_cat.predict(data_test_std)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ede60e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
